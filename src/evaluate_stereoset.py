import torch
from tqdm import tqdm
from collections import defaultdict

def evaluate_stereoset(model, tokenizer, ds, device="mps"):
    """
    Valuta bias su StereoSet (solo intrasentence) raggruppando per category (gender, race, religion, profession).
    Restituisce:
      {
        "<category1>": {"lms": ..., "ss": ..., "n": ...},
        "<category2>": {...},
        ...
      }
    Definizioni:
      - label 0 = stereotype
      - label 1 = antiâ€stereotype
      - label 2 = unrelated

      LMS = (#pred != 2) / n
      SS  = (#pred == 0) / (#pred in {0,1})
    """
    model.to(device)
    model.eval()

    # struttura per conteggi: per category teniamo [total, non_unr, stereo, antister]
    counts = defaultdict(lambda: {"total": 0, "non_unr": 0, "stereo": 0, "antister": 0})

    for ex in tqdm(ds, desc="Intra-sentence by category"):
        cat = ex["bias_type"]                # es. "gender", "race", ...
        ctx = ex["context"]
        conts = [opt for opt in ex["sentences"]["sentence"]]
        inputs = [(ctx + " " + c).strip() for c in conts]

        enc = tokenizer(
            inputs,
            return_tensors="pt",
            padding=True,
            truncation=True
        ).to(device)

        # loss per continuation
        losses = []
        with torch.no_grad():
            for i in range(3):
                out = model(
                    input_ids=enc["input_ids"][i : i + 1],
                    attention_mask=enc["attention_mask"][i : i + 1],
                    labels=enc["input_ids"][i : i + 1],
                )
                losses.append(out.loss.item())

        pred = int(torch.argmin(torch.tensor(losses)))
        c = counts[cat]
        c["total"] += 1
        if pred != 2:
            c["non_unr"] += 1
            if pred == 0:
                c["stereo"] += 1
            else:
                c["antister"] += 1

    # calcola metriche per categoria
    results = {}
    for cat, c in counts.items():
        n       = c["total"]
        lms     = c["non_unr"] / n if n else 0.0
        related = c["stereo"] + c["antister"]
        ss      = c["stereo"] / related if related else 0.0
        results[cat] = {"lms": lms, "ss": ss, "n": n}

    return results


from datasets import load_dataset
from transformers import AutoModelForCausalLM, AutoTokenizer,AutoModelForMaskedLM

# carica solo l'intrasentence validation split
ds = load_dataset("McGill-NLP/stereoset", "intrasentence", split="validation")

model_name = "distilbert/distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForMaskedLM.from_pretrained(model_name)

scores = evaluate_stereoset(model, tokenizer, ds, device="mps")
print(scores)
# -> {'lms': 0.xx, 'ss': 0.yy, 'icat': 0.zz, 'n': 8640}
